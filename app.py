import streamlit as st
import torch
from torchvision import transforms
from PIL import Image
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ–∂–Ω—ã—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π",
    page_icon="ü©∫",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
st.title("ü©∫ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ–∂–Ω—ã—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π")

# –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
st.warning(
    "‚ö†Ô∏è **–í–∞–∂–Ω–æ!** –î–∞–Ω–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, "
    "–Ω–æ –æ–Ω–æ **–Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–º**. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–º–∏. "
    "–î–ª—è —Ç–æ—á–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –≤—Ä–∞—á—É-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É."
)

st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–æ–∂–∏, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ.")

# –í–≤–æ–¥ –ø—É—Ç–µ–π –∫ –º–æ–¥–µ–ª–∏ –∏ labels.txt
model_path = st.text_input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏", "/home/eraly/Skin-ai/skin_disease_model_jit.pt")
labels_path = st.text_input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É labels.txt", "/home/eraly/Skin-ai/labels.txt")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏
if not os.path.exists(model_path):
    st.error(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
    st.stop()

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
model = torch.jit.load(model_path, map_location=torch.device('cpu'))
model.eval()

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è labels.txt
if not os.path.exists(labels_path):
    st.error("–§–∞–π–ª –º–µ—Ç–æ–∫ (labels.txt) –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    st.stop()

with open(labels_path, "r") as f:
    labels = [line.strip() for line in f.readlines()]

# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", type=["jpg", "jpeg", "png"], key="file_uploader")

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ RGB
    st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)

    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∑–∞–≥—Ä—É–∑–∫–∏
    progress_bar = st.progress(0)
    for i in range(100):
        progress_bar.progress(i + 1)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    try:
        with st.spinner("–ú–æ–¥–µ–ª—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ..."):
            image_tensor = preprocess(image).unsqueeze(0)
            with torch.no_grad():
                output = model(image_tensor)

            scores = torch.nn.functional.softmax(output[0], dim=0)
            max_score_index = torch.argmax(scores).item()
            predicted_class = labels[max_score_index]
            confidence = scores[max_score_index].item()

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        st.markdown(f"""
            ### üè• –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:
            - **–†–µ–∑—É–ª—å—Ç–∞—Ç:** `{predicted_class}`
            - **–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:** `{confidence:.2f}`
        """)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")

else:
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
